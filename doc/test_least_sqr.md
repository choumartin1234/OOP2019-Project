## 拓展功能 ：Assign

我们实现了给```Variable```赋值的```Assign```运算，同时会将其用在之后使用的测试。



## 拓展功能测试 ：优化最小二乘法

对于多变量线性函数 $f(\vec{x}) = \sum_{i=1}^n k_i x_i + b$, 我们实现了梯度下降优化最小二乘法的功能。其测试程序（包含```Assign```的使用测试在```example\test_leastsqr.cpp```, 可利用```make leastsqr```编译生成```test.exe```进行测试。

过程与思路 : 令 $A_{m \times (n+1)} =  \left[\begin{matrix}x_{11} & ... & x_{1n}&1\\...&...&...&... \\ x_{m1}&... & x_{mn} &1\end{matrix} \right] $,  $\vec{k}= (k_1,...,k_n, b)^T$, $\vec{y} = (y_1,...,y_m)^T$ 

我们可将原问题转化为优化 $\vec{k}$ , 使得损失函数 $L(\vec\omega) = ||A\vec{k} - \vec{y}||_2^2$  最小 , 利用梯度下降法迭代求解 :

$$\vec{k}^{i+1} =  \vec{k}^i  -\eta \nabla L(\vec{k}^i)$$ , 其中 $\eta$ 为学习速度 , 迭代次数为$epoches$。

我们利用计算图将$A$以及 $\vec{y}$ 设为```Constant```, 将$\vec{k}$ 设为```Variable```。每次迭代计算$\nabla L(\vec{k})$, 并利用```Assign```运算进行$\vec{k}$的修改与输出。每次迭代输出结果即为优化后的 $\vec{k}$ , 每轮迭代就输出一次。最后再输出训练后函数、参数值、优化结果$$A\vec{k} - \vec{y}$$。初值设定 : $\vec{k}_0 = (1,1,1)^T$ ,  $\eta = 0.02,   epoches= 1500$。

输入格式 : 

+ 第一行输入一个正整数以及一个浮点数, 分别代表迭代次数$epoches$ 以及学习速度 $ \eta$
+ 第二行输入两个正整数，分别表示样点数目 $m$ 以及空间维数 $n$。
+ 接下来 $m$ 行, 每行 $n+1$ 个浮点数, 表示第 $i$ 个样本点的坐标 $(x_{i1},x_{i2},...,x_{in})$ 以及实际值 $(y_i)$

样例输入 (leastsqr.in):

```
1500 0.03
4 2
3 2 4
2 2 7
1 2 2
0 1 5
```

样例输出 

``` c++
f(x) = 0.999949 * x_1 + -2.66647 * x_2 + 7.6664

k[1] = 0.999949
k[2] = -2.66647
b = 7.6664

The optimization of A*k-y is :
[[1.3333], [-2.6667], [1.3334], [-0.0001]]
```

测试结果 : 

![](pic\sqr1.jpg)



发现已趋于收敛, 更改初值为$\vec{k}_0 = (1, -2.6, 7.5)^T$ 再进行测试。

![](pic\sqr2.JPG)

梯度下降得到的 $\vec{k}= (0.9999, -2.666, 7.666)^T$ , 优化结果$$A\vec{k} - \vec{y} = (1.333, -2.666,1.3334,-0.0001)^T$$

与最小二乘法的公式法 :  $\vec\omega = (A^TA)^{-1}A^Ty$  进行对比。编写$matlab$程序得到结果如下：

![](pic\sqr3.JPG)

最小二乘得到的 $\vec{k}= (1, -8/3 , 22/3)^T$ ，优化结果$$A\vec{k} - \vec{y} = (4/3, -8/3, 4/3, 0)^T$$。 两者相符。











